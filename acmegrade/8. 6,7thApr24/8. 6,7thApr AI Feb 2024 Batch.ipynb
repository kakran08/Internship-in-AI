{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30bd4263",
   "metadata": {},
   "source": [
    "# Image Recognition using CNN on CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597bd3c",
   "metadata": {},
   "source": [
    "In this project we will be using CIFAR-10 dataset. This dataset includes thousands of pictures of 10 different kinds of objects like airplanes, automobiles, birds and so on.\n",
    "\n",
    "Each image in the dataset includes a matching label so we know what kind of image it is.\n",
    "\n",
    "The images in the CIFAR-10 dataset are only 32x32 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24ce56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb069e",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156f7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test, y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af706aed",
   "metadata": {},
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbdfdcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255.0\n",
    "X_test/=255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e480f4",
   "metadata": {},
   "source": [
    "Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201983eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff1d20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=(32,32,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f1595",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a81a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               590336    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 642570 (2.45 MB)\n",
      "Trainable params: 642570 (2.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b42b602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Mohit Tripathi\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1563/1563 [==============================] - 113s 70ms/step - loss: 1.5263 - accuracy: 0.4438 - val_loss: 1.1516 - val_accuracy: 0.5893\n",
      "Epoch 2/12\n",
      "1563/1563 [==============================] - 93s 59ms/step - loss: 1.1363 - accuracy: 0.5954 - val_loss: 0.9808 - val_accuracy: 0.6573\n",
      "Epoch 3/12\n",
      "1563/1563 [==============================] - 79s 51ms/step - loss: 0.9927 - accuracy: 0.6508 - val_loss: 0.9297 - val_accuracy: 0.6723\n",
      "Epoch 4/12\n",
      "1563/1563 [==============================] - 89s 57ms/step - loss: 0.9105 - accuracy: 0.6826 - val_loss: 0.8158 - val_accuracy: 0.7172\n",
      "Epoch 5/12\n",
      "1563/1563 [==============================] - 91s 58ms/step - loss: 0.8433 - accuracy: 0.7049 - val_loss: 0.7583 - val_accuracy: 0.7342\n",
      "Epoch 6/12\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.8013 - accuracy: 0.7206 - val_loss: 0.7288 - val_accuracy: 0.7478\n",
      "Epoch 7/12\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.7683 - accuracy: 0.7299 - val_loss: 0.7427 - val_accuracy: 0.7434\n",
      "Epoch 8/12\n",
      "1563/1563 [==============================] - 109s 70ms/step - loss: 0.7400 - accuracy: 0.7405 - val_loss: 0.7202 - val_accuracy: 0.7520\n",
      "Epoch 9/12\n",
      "1563/1563 [==============================] - 106s 68ms/step - loss: 0.7123 - accuracy: 0.7504 - val_loss: 0.7168 - val_accuracy: 0.7533\n",
      "Epoch 10/12\n",
      "1563/1563 [==============================] - 108s 69ms/step - loss: 0.6999 - accuracy: 0.7566 - val_loss: 0.6927 - val_accuracy: 0.7607\n",
      "Epoch 11/12\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.6858 - accuracy: 0.7591 - val_loss: 0.6609 - val_accuracy: 0.7729\n",
      "Epoch 12/12\n",
      "1563/1563 [==============================] - 107s 68ms/step - loss: 0.6614 - accuracy: 0.7679 - val_loss: 0.6812 - val_accuracy: 0.7654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x224d55789a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=12,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f0f36",
   "metadata": {},
   "source": [
    "Save the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb9cfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6342"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_structure=model.to_json()\n",
    "f=Path(\"model_structure.json\")\n",
    "f.write_text(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed7c1b",
   "metadata": {},
   "source": [
    "Save the trained neural network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cd2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b568731",
   "metadata": {},
   "source": [
    "Making Predictions on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76d19ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62617240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels=[\n",
    "    \"Planes\",\n",
    "    \"car\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Boat\",\n",
    "    \"Truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b15ffe",
   "metadata": {},
   "source": [
    "load the json file that contains the mdoel structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87fe056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=Path(\"model_structure.json\")\n",
    "model_structure=f.read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a9eee",
   "metadata": {},
   "source": [
    "Recreate the keras modeel bject from the json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c35249f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_from_json(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff843e6",
   "metadata": {},
   "source": [
    "reload the model training weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74bbbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_weight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dac264",
   "metadata": {},
   "source": [
    "Load an image file to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca1a66e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x224ff3606d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "img=load_img(\"dog.png\",target_size=(32,32))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8528993",
   "metadata": {},
   "source": [
    "Convert the image to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2741db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array\n",
    "image_to_test=img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fea90a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images=np.expand_dims(image_to_test,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24ed27",
   "metadata": {},
   "source": [
    "make predictions using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd2bf328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 286ms/step\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(list_of_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67708a4d",
   "metadata": {},
   "source": [
    "since we are only testing one image, we only need to check the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27844d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_result=results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a4bd7",
   "metadata": {},
   "source": [
    "We will get a likeliood score for all 10 possible classes. Find out which class has the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb93f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_class_index=int(np.argmax(single_result))\n",
    "class_likelihood=single_result[most_likely_class_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c78f38",
   "metadata": {},
   "source": [
    "Get the name of the most likely class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53992b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label=class_labels[most_likely_class_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b763bc",
   "metadata": {},
   "source": [
    "Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b0f75bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a image is a Dog likelihood: 1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"This is a image is a {} likelihood: {:2f}\".format(class_label, class_likelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f2e24",
   "metadata": {},
   "source": [
    "# Sentiment Classification using NLP and Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a60bc",
   "metadata": {},
   "source": [
    "Sentiment Analysis is a means to identofy the view or emotion behind a situation.\n",
    "\n",
    "It basically means to analyse and find the emotion or intent behind a piece of text or speech or any model of communication.\n",
    "\n",
    "This burger has a very bad taste- negative review\n",
    "\n",
    "I ordered this pizza today- nutral sentiment/review\n",
    "\n",
    "I love this cheese sandwich, its so delicious- positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11b9ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b005a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "082d9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d0b0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d773bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"train.txt\",delimiter=\";\",names=['text','label'])\n",
    "df_val=pd.read_csv(\"val.txt\",delimiter=\";\",names=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73cd745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df_train, df_val])\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f7974e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe:  (18000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>i plan to run miles in the morning which is a ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>i told him that if he touched me with a needle...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>i think this will help somebody out there that...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7131</th>\n",
       "      <td>i feel like my dream of being a good guitarist...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>i feel this way about all relationships romant...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    label\n",
       "5712   i plan to run miles in the morning which is a ...     love\n",
       "11294  i told him that if he touched me with a needle...    anger\n",
       "3095   i think this will help somebody out there that...  sadness\n",
       "7131   i feel like my dream of being a good guitarist...      joy\n",
       "9647   i feel this way about all relationships romant...     love"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of the dataframe: \",df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbcc8cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.countplot(df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deeaa9a",
   "metadata": {},
   "source": [
    "Positve Sentiment- joy, love, surprise\n",
    "\n",
    "Negative sentiment- anger, sadness, fear\n",
    "\n",
    "Now we will create a custom encoder to convert categorical target labels to numerical i.e 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "675fefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_encoder(df):\n",
    "    df.replace(to_replace=\"surprise\",value=1, inplace=True)\n",
    "    df.replace(to_replace=\"love\",value=1, inplace=True)\n",
    "    df.replace(to_replace=\"joy\",value=1, inplace=True)\n",
    "    df.replace(to_replace=\"fear\",value=0, inplace=True)\n",
    "    df.replace(to_replace=\"anger\",value=0, inplace=True)\n",
    "    df.replace(to_replace=\"sadness\",value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6e15076",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_encoder(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3548d936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e2f2f",
   "metadata": {},
   "source": [
    "Preprocessing Steps\n",
    "\n",
    "Get rid of any characters apart from alphabets\n",
    "\n",
    "Convert the string to lowercase because Python is case-sensitive\n",
    "\n",
    "3 Check and remove the stopwords\n",
    "\n",
    "Perform lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "508837ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf0e8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transformation(df_col):\n",
    "    corpus=[]\n",
    "    for item in df_col:\n",
    "        new_item=re.sub('[^a-zA-Z]',' ',str(item))\n",
    "        new_item=new_item.lower()\n",
    "        new_item=new_item.split()\n",
    "        new_item=[lm.lemmatize(word) for word in new_item if word not in set(stopwords.words('english'))]\n",
    "        corpus.append(' '.join(str(x) for x in new_item))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60b6cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=text_transformation(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bbc8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "traindata=cv.fit_transform(corpus)\n",
    "X=traindata\n",
    "y=df.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34263a2",
   "metadata": {},
   "source": [
    "Now we will fit the data into grid search and view the best parameters using the best_params attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93caf195",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'max_features':('auto','sqrt'),\n",
    "            'n_estimators':[5,10],\n",
    "            'max_depth':[10,None],\n",
    "            'min_samples_split':[5],\n",
    "            'min_samples_leaf':[1],\n",
    "            'bootstrap':[True]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab2e14e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search=GridSearchCV(RandomForestClassifier(), parameters, cv=5, return_train_score=True,n_jobs=-1)\n",
    "grid_search.fit(X,y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3375137",
   "metadata": {},
   "source": [
    "We can view all the models and their respective parameters, mean test score and rank as GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7ab03f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.5970000000000001\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.6148333333333333\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.5953888888888889\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.6165\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.9119444444444443\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.9382222222222222\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 5}\n",
      "Mean test Score:  0.9145\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n",
      "Parameters:  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Mean test Score:  0.9392222222222223\n",
      "Rank:  [7 6 8 5 4 2 3 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print('Parameters: ', grid_search.cv_results_['params'][i])\n",
    "    print('Mean test Score: ',grid_search.cv_results_['mean_test_score'][i])\n",
    "    print(\"Rank: \",grid_search.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de70e4",
   "metadata": {},
   "source": [
    "Now we will choose the best parameter obtained from GridSearchCV and create a final random forest classifier model and then train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2872d8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', min_samples_split=5,\n",
       "                       n_estimators=10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc= RandomForestClassifier(max_features=grid_search.best_params_['max_features'],\n",
    "                           max_depth=grid_search.best_params_['max_depth'],\n",
    "                           n_estimators=grid_search.best_params_['n_estimators'],\n",
    "                           min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                           min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
    "                           bootstrap=grid_search.best_params_['bootstrap'])\n",
    "\n",
    "rfc.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2bbf57",
   "metadata": {},
   "source": [
    "Test Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1bf64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('test.txt',delimiter=';',names=['text','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b42da02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test=test_df.text, test_df.label\n",
    "\n",
    "# encode the labels into two classes 0 and 1\n",
    "test_df= custom_encoder(y_test)\n",
    "\n",
    "# preprocessing of text\n",
    "test_corpus=text_transformation(X_test)\n",
    "\n",
    "# convert the text data into vectors\n",
    "testdata=cv.transform(test_corpus)\n",
    "\n",
    "#predict the target\n",
    "predictions=rfc.predict(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e943c8",
   "metadata": {},
   "source": [
    "Model Evaluation\n",
    "\n",
    "We will evaluate our model using various metrics such as accuracy score, precision score, recall score confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3964353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9485\n",
      "Precision Score: 0.9584736251402918\n",
      "Recall Score 0.9282608695652174\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      1080\n",
      "           1       0.96      0.93      0.94       920\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_score= accuracy_score(y_test, predictions)\n",
    "pre_score= precision_score(y_test, predictions)\n",
    "rec_score=recall_score(y_test, predictions)\n",
    "\n",
    "print('Accuracy Score:',acc_score)\n",
    "print(\"Precision Score:\",pre_score)\n",
    "print('Recall Score',rec_score)\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "cr=classification_report(y_test, predictions)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14424aa7",
   "metadata": {},
   "source": [
    "ROC Curve- We will plot probability of the class using the predict_proba() method of random forest classifier and then we will plot the cureve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8ce6da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_probability= rfc.predict_proba(testdata)\n",
    "fpr,tpr,thresholds=roc_curve(y_test, predictions_probability[:,1])\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1])\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e14ff6",
   "metadata": {},
   "source": [
    "As we cna see that our model performed very well in classifying the sentiments, with an accuracy score, precision score and recall score of approx 96%.\n",
    "\n",
    "Now we will check for custom input as well and let our model identify the sentiment of the input statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25e6f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expression_check(prediction_input):\n",
    "    if prediction_input==0:\n",
    "        print(\"Input statement has negative sentiment\")\n",
    "    elif prediction_input==1:\n",
    "        print(\"Input statement has positive sentiment\")\n",
    "    else:\n",
    "        print(\"Invalid Statement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886155d7",
   "metadata": {},
   "source": [
    "Function to take the input statement and performs the same transformation as we did earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c02d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predictor(input):\n",
    "    input=text_transformation(input)\n",
    "    transformed_input=cv.transform(input)\n",
    "    prediction=rfc.predict(transformed_input)\n",
    "    expression_check(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88953cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=[\"Sometimes I just don't want to go out\"]\n",
    "input2=[\"I bought a new phone and it's so good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32c16ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input statement has negative sentiment\n",
      "Input statement has positive sentiment\n"
     ]
    }
   ],
   "source": [
    "sentiment_predictor(input1)\n",
    "sentiment_predictor(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e695b9",
   "metadata": {},
   "source": [
    "# Chatbot using NLP and Neural Networks in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a8176",
   "metadata": {},
   "source": [
    "Tag means classes\n",
    "\n",
    "Patterns means what user is going to ask\n",
    "\n",
    "Response is chatbot response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b48739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"intents\":[\n",
    "    {\"tag\":\"greeting\",\n",
    "     \"patterns\":[\"Hello\",\"How are you?\",\"Hi There\",\"Hi\",\"What's up\"],\n",
    "     \"responses\":[\"Howdy Partner!\",\"Hello\",\"How are you doing?\",\"Greetings!\",\"How do you do\"]\n",
    "        },\n",
    "    {\"tag\":\"age\",\n",
    "     \"patterns\":[\"how old are you\",\"when is your birthday\",\"when was you born\"],\n",
    "     \"responses\":[\"I am 24 years old\",\"I was born in 1966\",\"My birthday is July 3rd and I was born in 1996\",\"03/07/1996\"]\n",
    "        },\n",
    "    {\"tag\":\"date\",\n",
    "     \"patterns\":[\"what are you doing this weekend\",\n",
    "                \"do you want to hangout sometime?\",\"what are your plans for this week\"],\n",
    "     \"responses\":[\"I am available this week\",\"I don't have any plans\",\"I am not busy\"]\n",
    "        },\n",
    "    {\"tag\":\"name\",\n",
    "     \"patterns\":[\"what's your name\",\"what are you called\",\"who are you\"],\n",
    "     \"responses\":[\"My name is Kippi\",\"I'm Kippi\",\"Kippi\"]\n",
    "        },\n",
    "    {\"tag\":\"goodbye\",\n",
    "     \"patterns\":[\"bye\",\"g2g\",\"see ya\",\"adios\",\"cya\"],\n",
    "     \"responses\":[\"It was nice speaking to you\",\"See you later\",\"Speak Soon\"]\n",
    "        },\n",
    "]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628db0e6",
   "metadata": {},
   "source": [
    "For each tag we created, we would specify patterns. Essentially this defines the different ways of how a user may pose a query to the chatbot.\n",
    "\n",
    "The chatbot would then take these patterns and use them as training data to determine what someone is asking and the chatbot response would be relevant to that qustion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6204dad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohit\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mohit\n",
      "[nltk_data]     Tripathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da5f25",
   "metadata": {},
   "source": [
    "In order to create our training data below steps to be followed\n",
    "\n",
    "Create a vocabulary of all the words used in the patterns\n",
    "\n",
    "Create a list of the classes- tage of ach intent\n",
    "\n",
    "Create a list of all the patterns within the intents file\n",
    "\n",
    "Create a list of all the associated tags to go with each patterns in the intents file.\n",
    "\n",
    "Initialising lemmatier to get stem of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa7275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "words=[]\n",
    "classes=[]\n",
    "doc_x=[]\n",
    "doc_y=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a695d9",
   "metadata": {},
   "source": [
    "Loop through all the intents\n",
    "\n",
    "Tokenize each patter and append token to words, the patterns and the associated tag to their associated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb8245f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        tokens=nltk.word_tokenize(pattern)\n",
    "        words.extend(tokens)\n",
    "        doc_x.append(pattern)\n",
    "        doc_y.append(intent[\"tag\"])\n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd03d5e",
   "metadata": {},
   "source": [
    "Lemmatize all the words in the vocab and convert them to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30b98269",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f919fc7",
   "metadata": {},
   "source": [
    "Sorting the vocab and classes in alphabeical order and taking the set to ensure no duplicates occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2a03711",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=sorted(set(words))\n",
    "classes=sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eaea03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'adios', 'are', 'birthday', 'born', 'bye', 'called', 'cya', 'do', 'doing', 'for', 'g2g', 'hangout', 'hello', 'hi', 'how', 'is', 'name', 'old', 'plan', 'see', 'sometime', 'there', 'this', 'to', 'up', 'wa', 'want', 'week', 'weekend', 'what', 'when', 'who', 'ya', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53191290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'date', 'goodbye', 'greeting', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff1d24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'How are you?', 'Hi There', 'Hi', \"What's up\", 'how old are you', 'when is your birthday', 'when was you born', 'what are you doing this weekend', 'do you want to hangout sometime?', 'what are your plans for this week', \"what's your name\", 'what are you called', 'who are you', 'bye', 'g2g', 'see ya', 'adios', 'cya']\n"
     ]
    }
   ],
   "source": [
    "print(doc_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bf79313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'age', 'age', 'age', 'date', 'date', 'date', 'name', 'name', 'name', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye']\n"
     ]
    }
   ],
   "source": [
    "print(doc_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa8b3d",
   "metadata": {},
   "source": [
    "List for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab3d9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=[]\n",
    "out_empty=[0]*len(classes)\n",
    "\n",
    "# creating a bag of words model\n",
    "\n",
    "for idx, doc in enumerate(doc_x):\n",
    "    bow=[]\n",
    "    text=lemmatizer.lemmatize(doc.lower())\n",
    "    for word in words:\n",
    "        bow.append(1) if word in text else bow.append(0)\n",
    "    output_row=list(out_empty)\n",
    "    output_row[classes.index(doc_y[idx])]=1\n",
    "\n",
    "    training.append([bow, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "\n",
    "training=np.array(training,dtype=object)\n",
    "\n",
    "train_X=np.array(list(training[:,0]))\n",
    "train_y=np.array(list(training[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1ee1b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5968ee8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5b674c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(len(train_X[0]),)\n",
    "output_shape=len(train_y[0])\n",
    "\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40d42b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 128)               4736      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13317 (52.02 KB)\n",
      "Trainable params: 13317 (52.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(output_shape, activation='softmax'))\n",
    "\n",
    "# Create the Adam optimizer with a specified learning rate\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model using the Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c74bd839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6191 - accuracy: 0.1053\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5498 - accuracy: 0.3158\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3489 - accuracy: 0.5789\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2536 - accuracy: 0.6842\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1208 - accuracy: 0.8421\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0863 - accuracy: 0.7368\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0991 - accuracy: 0.6842\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8308 - accuracy: 0.8421\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6025 - accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4572 - accuracy: 0.9474\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5693 - accuracy: 0.8421\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3396 - accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3888 - accuracy: 0.8947\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2659 - accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2775 - accuracy: 0.8421\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2739 - accuracy: 0.9474\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.9474\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0790 - accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1430 - accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0912 - accuracy: 0.9474\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0643 - accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0983 - accuracy: 0.9474\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0511 - accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1826 - accuracy: 0.9474\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0644 - accuracy: 0.9474\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1345 - accuracy: 0.9474\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1881 - accuracy: 0.9474\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0849 - accuracy: 0.9474\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0544 - accuracy: 0.9474\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0415 - accuracy: 0.9474\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3285e-04 - accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0666 - accuracy: 0.9474\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0765 - accuracy: 0.9474\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.2841e-04 - accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1323 - accuracy: 0.9474\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1768 - accuracy: 0.9474\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.2564e-04 - accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8711e-04 - accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5295e-04 - accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0805 - accuracy: 0.9474\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.5153e-05 - accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1085 - accuracy: 0.9474\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.0553e-04 - accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3413e-04 - accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2504e-04 - accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 6.6927e-04 - accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.9043e-04 - accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6175e-04 - accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2240e-04 - accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.4894e-04 - accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.3287e-04 - accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3647 - accuracy: 0.9474\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.8418e-04 - accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3178e-04 - accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7211e-04 - accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.7134e-04 - accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6544e-04 - accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.2594e-04 - accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3052e-04 - accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8425e-04 - accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 8.4699e-04 - accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.7484e-04 - accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.3864e-04 - accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.2332e-04 - accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.3867e-04 - accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9026e-04 - accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.6943e-04 - accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8521e-04 - accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.9444e-04 - accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2614e-04 - accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9199e-04 - accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.7044e-04 - accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.8792e-04 - accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1192e-04 - accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.4723e-04 - accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5412e-04 - accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.9854e-04 - accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5302e-05 - accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.6637e-04 - accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4046e-04 - accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2264e-04 - accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.5444e-05 - accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.1107e-05 - accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.3743e-05 - accuracy: 1.0000\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6595e-04 - accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4523e-04 - accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3223e-04 - accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4504e-04 - accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1855e-05 - accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7515e-04 - accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2498e-04 - accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9982e-04 - accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0592e-04 - accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.1926e-05 - accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3746e-04 - accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.8043e-05 - accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.9717e-04 - accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.8609e-04 - accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.4939e-05 - accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.6924e-05 - accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1596e-04 - accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.4898e-04 - accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.4841e-04 - accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.8704e-05 - accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.3387e-05 - accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.1803e-05 - accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2647e-05 - accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4304e-05 - accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2781e-04 - accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5438e-04 - accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3556e-04 - accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2371e-04 - accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.6261e-04 - accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.6212e-04 - accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.5929e-05 - accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.8452e-04 - accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.7669e-06 - accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.6444e-04 - accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7849e-04 - accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.7350e-05 - accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.0450e-04 - accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2018e-05 - accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.9464e-06 - accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9230e-05 - accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.6537e-05 - accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.6363e-04 - accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.7994e-04 - accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0267e-04 - accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5595e-04 - accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.0181e-04 - accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.5349e-04 - accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1192e-05 - accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.6605e-04 - accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9861e-04 - accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.3206e-04 - accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.0060e-05 - accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.9690e-05 - accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.1405e-04 - accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.8903e-05 - accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0511e-04 - accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1230e-05 - accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9719e-05 - accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9023e-04 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1615e-04 - accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.1743e-05 - accuracy: 1.0000\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7334e-05 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.6928e-05 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6443e-05 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1636e-04 - accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2429e-05 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.8405e-05 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.0938e-05 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.5612e-06 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5911e-04 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2159e-05 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.7635e-05 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.5051e-04 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.1983e-05 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4109e-04 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6849e-04 - accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.6226e-05 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0239e-05 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6175e-04 - accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.3142e-05 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2297e-05 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9071e-04 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.3523e-05 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.1836e-05 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4712e-04 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.0499e-04 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.8702e-04 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1804e-05 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6922e-05 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7817e-04 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5349e-04 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3388e-05 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0442e-04 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.5200e-04 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.7880e-05 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.4621e-06 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.7482e-04 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.7251e-05 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.4869e-05 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9949e-04 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7115e-04 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.9329e-05 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5708e-04 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1568e-04 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1693e-04 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5102e-05 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2508e-04 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7541e-05 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1751e-04 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1318e-05 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2153e-04 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7533e-05 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7151e-04 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.0716e-04 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7577e-04 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9736e-04 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1369e-04 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5277e-04 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0904e-05 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2633e-04 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.3368e-06 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.8531e-05 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5680e-04 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.0665e-05 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.4197e-06 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0746e-04 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.6814e-05 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1506e-05 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2843e-04 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9205e-05 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4831e-05 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7932e-05 - accuracy: 1.0000\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1207e-05 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.7615e-04 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.4083e-05 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.3951e-05 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1586e-04 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4983e-04 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.0557e-05 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.9441e-05 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.1732e-04 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5288e-05 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3124e-05 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3367e-04 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.3720e-04 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.7572e-04 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1179e-04 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.5273e-05 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.0150e-05 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4759e-04 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.0029e-06 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1636e-04 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.2352e-05 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1494e-05 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.0995e-05 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1128e-04 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.2707e-04 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.6693e-04 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5045e-05 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8.2564e-06 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1808e-05 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1832e-05 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.1950e-05 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.1544e-04 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.3615e-05 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.4392e-05 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6248e-04 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 9.8640e-05 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1214e-04 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.7735e-05 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7052e-05 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.0060e-05 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.0949e-04 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.4609e-05 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2930e-05 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0492e-05 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0389e-05 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8777e-05 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.8212e-06 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.7635e-06 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.8292e-05 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.6229e-06 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.0090e-05 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.6622e-04 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.6114e-06 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1726e-05 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.4270e-05 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3641e-04 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.6830e-06 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.1335e-06 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3161e-04 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9005e-04 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.8827e-04 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.9883e-05 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0020e-04 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4485e-05 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1409e-06 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.8995e-05 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6659e-04 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1621e-05 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3253e-07 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6442e-05 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1647e-04 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.7520e-04 - accuracy: 1.0000\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.1221e-05 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.6038e-05 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4505e-05 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4612e-04 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8948e-04 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.8231e-05 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1532e-04 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0210e-05 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.4112e-07 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7466e-05 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5867e-05 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6546e-04 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.1924e-06 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6769e-04 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.6554e-06 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.9227e-06 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8912e-05 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.6394e-04 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.3897e-05 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3176e-06 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.4582e-05 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2222e-05 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.4897e-04 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0283e-05 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2548e-06 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.6802e-04 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.4103e-04 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.5787e-06 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0556e-04 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.1268e-05 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5698e-04 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4056e-05 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6843e-06 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8067e-05 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.5137e-06 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0145e-04 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.6338e-04 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.3592e-06 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.1199e-04 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3677e-05 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0014e-06 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2788e-05 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0853e-04 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.1837e-06 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.0593e-06 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.4590e-04 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9969e-05 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5703e-05 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.6052e-06 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2086e-04 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5822e-04 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.6582e-06 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.4270e-06 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.1583e-05 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.9782e-05 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5162e-04 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.9104e-04 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6990e-05 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.2330e-05 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.3604e-04 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0539e-05 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.9361e-05 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.5130e-05 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.9573e-05 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2319e-04 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0967e-05 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0014e-06 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.3194e-06 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9756e-05 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3991e-06 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.3772e-05 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.4094e-05 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.4046e-05 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2651e-04 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1546e-04 - accuracy: 1.0000\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 2.7471e-05 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.7470e-05 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0961e-04 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.3452e-04 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5159e-06 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6418e-04 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0320e-05 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.4511e-05 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.5250e-06 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.6276e-04 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3671e-05 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.6540e-05 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.9439e-06 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.2995e-05 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5016e-05 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.0041e-05 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7990e-05 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.6581e-06 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3569e-05 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0540e-05 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0891e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2250c07f7c0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_X, y=train_y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3314fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def bag_of_words(text,vocab):\n",
    "    tokens=clean_text(text)\n",
    "    bow=[0]*len(vocab)\n",
    "    for w in tokens:\n",
    "        for idx, word in enumerate(vocab):\n",
    "            if word==w:\n",
    "                bow[idx]=1\n",
    "    return np.array(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13d450d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_class(text, vocab,labels):\n",
    "    bow=bag_of_words(text, vocab)\n",
    "    result=model.predict(np.array([bow]))[0]\n",
    "    thresh=0.2\n",
    "    y_pred=[[idx,res] for idx, res in enumerate(result) if res>thresh]\n",
    "\n",
    "    y_pred.sort(key=lambda x:x[1], reverse=True)\n",
    "    return_list=[]\n",
    "    for r in y_pred:\n",
    "        return_list.append(labels[r[0]])\n",
    "    return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    tag=intents_list[0]\n",
    "    list_of_intents=intents_json[\"intents\"]\n",
    "    for i in list_of_intents:\n",
    "        if i[\"tag\"]==tag:\n",
    "            result=random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807e5a84",
   "metadata": {},
   "source": [
    "Running the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62e90948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "Hello\n",
      "what is your name\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "My name is Kippi\n",
      "goodbye\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "See you later\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     intents\u001b[38;5;241m=\u001b[39mpred_class(message, words, classes)\n\u001b[0;32m      4\u001b[0m     result\u001b[38;5;241m=\u001b[39mget_response(intents,data)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m     )\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message=input(\"\")\n",
    "    intents=pred_class(message, words, classes)\n",
    "    result=get_response(intents,data)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec89f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
